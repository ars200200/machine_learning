{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690dd4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsen/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/arsen/anaconda3/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "import tqdm \n",
    "import os\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b2b730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0674eaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "option_path = 'config.yml'\n",
    "with open(option_path, 'r') as file_options:\n",
    "    option = yaml.safe_load(file_options)\n",
    "option\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce60827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x7205bc87ec20>\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed8c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile as zf\n",
    "\n",
    "files = zf.ZipFile(\"archive.zip\",'r')\n",
    "files.extractall()\n",
    "files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39609805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['archive.zip',\n",
       " 'resnet.ipynb',\n",
       " 'dataset',\n",
       " 'pycharm-community-2023.2.5',\n",
       " '.ipynb_checkpoints',\n",
       " 'config.yml']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Dataset2class(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_dir1:str, path_dir2:str):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.path_dir1 = path_dir1\n",
    "        self.path_dir2 = path_dir2\n",
    "        \n",
    "        self.dir1_list = sorted(os.listdir(path_dir1))\n",
    "        self.dir2_list = sorted(os.listdir(path_dir2))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dir2_list) + len(self.dir1_list)\n",
    "    \n",
    "    def __getitem__(self, idx :int):\n",
    "        \n",
    "        if idx < len(self.dir1_list):\n",
    "            class_id = 0\n",
    "            img_path = os.path.join(self.path_dir1, self.dir1_list[idx])\n",
    "        else:\n",
    "            class_id = 1\n",
    "            idx -= len(self.dir1_list)\n",
    "            img_path = os.path.join(self.path_dir2, self.dir2_list[idx])\n",
    "        \n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.float32)\n",
    "        img /= 255.0\n",
    "        \n",
    "        img = cv2.resize(img, (64, 64),  interpolation = cv2.INTER_AREA)\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        \n",
    "        t_img = torch.from_numpy(img)\n",
    "        t_class_id = torch.tensor(class_id)\n",
    "        \n",
    "        return {'img': t_img, 'label': t_class_id}\n",
    "        \n",
    "        \n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68e77ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_catsdogs = Dataset2class(\n",
    "    './dataset/training_set/dogs',\n",
    "    './dataset/training_set/cats'\n",
    ")\n",
    "\n",
    "test_ds_catsdogs = Dataset2class(\n",
    "    './dataset/test_set/dogs',\n",
    "    './dataset/test_set/cats'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08246746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds_catsdogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db03ebaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds_catsdogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a49eb282",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = option['batch_size']\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds_catsdogs, shuffle=True,\n",
    "    batch_size=batch_size, num_workers=0, drop_last=True\n",
    "    \n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds_catsdogs, shuffle=True,\n",
    "    batch_size=batch_size, num_workers=0\n",
    "    \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5021f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.conv0  = nn.Conv2d(3, 128, 3, stride=1, padding=0)\n",
    "        self.conv1  = nn.Conv2d(128, 128, 3, stride=1, padding=0)\n",
    "        self.conv2  = nn.Conv2d(128, 128, 3, stride=1, padding=0)\n",
    "        self.conv3  = nn.Conv2d(128, 256, 3, stride=1, padding=0)\n",
    "        \n",
    "        self.adaptivepool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.linear = nn.Linear(256, 20)\n",
    "        self.linear2 = nn.Linear(20, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv0(x)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.act(out)\n",
    "\n",
    "        out = self.adaptivepool(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.act(out)\n",
    "        out = self.linear2(out)\n",
    "    \n",
    "\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd8f9fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (act): LeakyReLU(negative_slope=0.2)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (adaptivepool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=256, out_features=20, bias=True)\n",
       "  (linear2): Linear(in_features=20, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e59a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_loader:\n",
    "    \n",
    "    img = sample['img']\n",
    "    label = sample['label']\n",
    "    model(img)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4e8b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas = (0.9, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2b7fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, label):\n",
    "    answer = F.softmax(pred.detach()).numpy().argmax(1) == label.numpy().argmax(1)\n",
    "    return answer.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9387d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "710f609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_amp = True \n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b812efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                         | 0/500 [00:00<?, ?it/s]/tmp/ipykernel_120508/1416373963.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  answer = F.softmax(pred.detach()).numpy().argmax(1) == label.numpy().argmax(1)\n",
      "loss:6.5247e-01\taccuracy: 0.625: 100%|██████████████████████████████| 500/500 [00:38<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69713021671772\n",
      "0.51525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:5.9850e-01\taccuracy: 0.625: 100%|██████████████████████████████| 500/500 [00:40<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6844596691727638\n",
      "0.557875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:7.3508e-01\taccuracy: 0.500: 100%|██████████████████████████████| 500/500 [00:40<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6557248861193657\n",
      "0.625125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:5.9182e-01\taccuracy: 0.812: 100%|██████████████████████████████| 500/500 [00:43<00:00, 11.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5896937477588654\n",
      "0.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:5.6328e-01\taccuracy: 0.688: 100%|██████████████████████████████| 500/500 [00:42<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5253394937515259\n",
      "0.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:3.2254e-01\taccuracy: 0.875: 100%|██████████████████████████████| 500/500 [00:41<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47260719975829124\n",
      "0.777125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:3.9718e-01\taccuracy: 0.750: 100%|██████████████████████████████| 500/500 [00:39<00:00, 12.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42476305413246157\n",
      "0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:2.7369e-01\taccuracy: 0.875: 100%|██████████████████████████████| 500/500 [00:41<00:00, 12.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37728972312808035\n",
      "0.828875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:4.4420e-01\taccuracy: 0.812: 100%|██████████████████████████████| 500/500 [00:41<00:00, 12.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32469331776350735\n",
      "0.853125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:3.2256e-01\taccuracy: 0.812: 100%|██████████████████████████████| 500/500 [00:41<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2876426797695458\n",
      "0.87125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:1.0215e-01\taccuracy: 1.000: 100%|██████████████████████████████| 500/500 [00:40<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25973121117800474\n",
      "0.888125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:1.0176e-01\taccuracy: 1.000: 100%|██████████████████████████████| 500/500 [00:42<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22051145405042916\n",
      "0.90325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:2.1154e-01\taccuracy: 0.875: 100%|██████████████████████████████| 500/500 [00:39<00:00, 12.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18404810046590864\n",
      "0.92225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:1.2384e-01\taccuracy: 0.938: 100%|██████████████████████████████| 500/500 [00:39<00:00, 12.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14860196528676897\n",
      "0.940125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:6.4953e-02\taccuracy: 1.000: 100%|██████████████████████████████| 500/500 [00:39<00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12899580410774797\n",
      "0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss:4.2205e-01\taccuracy: 0.812: 100%|██████████████████████████████| 500/500 [00:38<00:00, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10801605780026875\n",
      "0.955125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 16\n",
    "for epoch in range(epochs):\n",
    "    loss_val = 0\n",
    "    acc_val = 0\n",
    "    for sample in (pbar := tqdm.tqdm(train_loader)):\n",
    "        \n",
    "        img, label = sample['img'], sample['label']\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        opimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "\n",
    "        label = F.one_hot(label, 2).float()\n",
    "            \n",
    "        pred = model(img)\n",
    "        loss = loss_fn(pred, label)\n",
    "\n",
    "        loss.backward()\n",
    "        loss_item = loss.item()\n",
    "        loss_val += loss_item\n",
    "        \n",
    "        opimizer.step()\n",
    "        acc_current = accuracy(pred.cpu(), label.cpu())\n",
    "        acc_val += acc_current\n",
    "\n",
    "        pbar.set_description(f'loss:{loss_item:.4e}\\taccuracy: {acc_current:.3f}')\n",
    "    print(loss_val/len(train_loader))\n",
    "    print(acc_val/len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1e9b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = tv.models.resnet.resnet34()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a170f624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "735a84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, nc):\n",
    "        super().__init__()\n",
    "        self.conv0 = nn.Conv2d(nc, nc, kernel_size = 3, padding = 1)\n",
    "        self.norm0 = nn.BatchNorm2d(nc)\n",
    "        self.act = nn.LeakyReLU(0.2 , inplace = True)\n",
    "        self.conv1 = nn.Conv2d(nc, nc, kernel_size = 3, padding = 1)\n",
    "        self.norm1 = nn.BatchNorm2d(nc)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv0(x)\n",
    "        out = self.norm0(out)\n",
    "        out = self.act(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.norm1(out)\n",
    "\n",
    "        return self.act(x + out)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01f06f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResTruck(nn.Module):\n",
    "    def __init__(self, nc, num_blocks):\n",
    "        super().__init__()\n",
    "        truck = []\n",
    "        for i in range(num_blocks):\n",
    "            truck += [(ResBlock(nc))]\n",
    "        self.truck = nn.Sequential(*truck)\n",
    "    def forward(self, x):\n",
    "        return self.truck(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4661ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseResNet(nn.Module):\n",
    "    def __init__(self, in_nc, nc, out_nc):\n",
    "        super().__init__()\n",
    "        self.conv0 = nn.Conv2d(in_nc, nc, kernel_size=7, stride=2)\n",
    "        #self.norm\n",
    "        self.act = nn.LeakyReLU(0.2, inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.layer1 = ResTruck(nc, 3)\n",
    "        self.conv1 = nn.Conv2d(nc, 2*nc, 3, padding=1, stride=2)\n",
    "        self.layer2 = ResTruck(2*nc, 4)\n",
    "        self.conv2 = nn.Conv2d(2*nc, 4*nc, 3, padding=1, stride=2)\n",
    "        self.layer3 = ResTruck(4*nc, 6)\n",
    "        self.conv3 = nn.Conv2d(4*nc, 4*nc, 3, padding=1, stride=2)\n",
    "        self.layer4 = ResTruck(4*nc, 3)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.linear = nn.Linear(4*nc, out_nc)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv0(x)\n",
    "        out = self.act(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        \n",
    "        out = self.avgpool(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f298fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PseResNet(3, 32, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d18fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "952c0e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3258370"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a038bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "for i, sample in enumerate(train_loader):\n",
    "    img = sample['img'].to(device)\n",
    "    label = sample['label'].to(device)\n",
    "    \n",
    "    model(img)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c63131f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7929a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d98d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                         | 0/500 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    loss_val = 0\n",
    "    acc_val = 0\n",
    "    for sample in (pbar := tqdm.tqdm(train_loader)):\n",
    "        img, label = sample['img'], sample['label']\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        opimizer.zero_grad()\n",
    "        label = F.one_hot(label, 2).float()\n",
    "            \n",
    "        \n",
    "        pred = model(img)\n",
    "\n",
    "        loss = loss_fn(pred, label)\n",
    "\n",
    "        loss.backward()\n",
    "        loss_item = loss.item()\n",
    "        loss_val += loss_item\n",
    "        \n",
    "        opimizer.step()\n",
    "        acc_current = accuracy(pred.cpu().float(), label.cpu().float())\n",
    "        acc_val += acc_current\n",
    "\n",
    "    pbar.set_description(f'loss:{loss_item:.4e}\\taccuracy: {acc_current:.3f}')\n",
    "    print(loss_val/len(train_loader))\n",
    "    print(acc_val/len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c11e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016c12b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
